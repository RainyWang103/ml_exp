{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 6 Clustering & NN (ch11&13)\n",
    "\n",
    "## Wang Yuli 3035028946\n",
    "\n",
    "This assignment has weighting $3.5$.\n",
    "The first question about clustering has 35%, and the second question about tiny image classification has 65%.\n",
    "\n",
    "This is a challenging assignment, so I recommend you start early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clustering for handwritten digits\n",
    "\n",
    "Supervised learning requires labeled data, which can be expensive to acquire.\n",
    "For example, a dataset with $N$ samples for classification will require manual labeling $N$ times.\n",
    "\n",
    "One way to ameliorate this issue is to perform clustering of the raw data samples first, followed by manual inspection and labeling of only a few samples.\n",
    "Recall that clustering is a form of non-supervised learning, so it does not require any class labels.\n",
    "\n",
    "For example, say we are given a set of scanned hand-written digit images.\n",
    "We can cluster them into 10 groups first, manually inspect and label a few images in each cluster, and propagate the label towards the rest of all (unlabeled) samples in each cluster.\n",
    "\n",
    "The accuracy of such semi-automatic labeling depends on the accuracy of the clustering.\n",
    "If each cluster (0 to 9) corresponds exactly to hand-written digits 0-9, we are fine.\n",
    "Otherwise, we have some mis-labeled data.\n",
    "\n",
    "The goal of this question is to exercise clustering of the scikit-learn digits dataset which has labels, so that we can verify our clustering accuracy.\n",
    "The specifics are as follows.\n",
    "\n",
    "You will be judged by the test accuracy of your code, and quality of descriptions of your method.\n",
    "As a reference, a simple code I (Li-Yi) wrote can achieve about 78% accuracy. Try to beat it as much as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training and test data split\n",
    "\n",
    "We will split the original dataset into training and test datasets\n",
    "* training for building our clusters\n",
    "* testing to see if the clusters can predict future data\n",
    "\n",
    "## Accuracy\n",
    "What is your clustering accuracy (comparing cluster labels with the ground truth labels), and what are the properties of mis-clustered samples?\n",
    "\n",
    "## Data preprocessing\n",
    "Would the original features (pixels) work well, or we need further processing like scaling/standardization or dimensionality-reduction, before clustering?\n",
    "\n",
    "## Models and hyper-parameters\n",
    "\n",
    "Let's focus on k-means clustering, as hierarchical and density-based clustering do not provide the predict() method under scikit-learn.\n",
    "\n",
    "What is the best test performance you can achieve with which hyper-parameters (for k-means, standard scalar, and dimensionality reduction)?\n",
    "\n",
    "### Hint\n",
    "We have learned Pipeline and GridSearchCV for cross validation and hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "last updated: 2016-12-19 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.1\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "scipy 0.17.1\n",
      "sklearn 0.18\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a '' -u -d -v -p numpy,pandas,matplotlib,scipy,sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Added version check for recent scikit-learn 0.18 checks\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data # data in pixels\n",
    "y = digits.target # digit labels\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEZCAYAAADCJLEQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0G9cRSgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b61d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "num_rows = 4\n",
    "num_cols = 5\n",
    "\n",
    "fig, ax = plt.subplots(nrows=num_rows, ncols=num_cols, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for index in range(num_rows*num_cols):\n",
    "    img = digits.images[index]\n",
    "    label = digits.target[index]\n",
    "    ax[index].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    ax[index].set_title('digit ' + str(label))\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Data sets: training versus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1257, test: 540\n"
     ]
    }
   ],
   "source": [
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "num_training = y_train.shape[0]\n",
    "num_test = y_test.shape[0]\n",
    "print('training: ' + str(num_training) + ', test: ' + str(num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119 133 128 119 120 135 130 122 128 123]\n",
      "[59 49 49 64 61 47 51 57 46 57]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# check to see if the data are well distributed among digits\n",
    "for y in [y_train, y_test]:\n",
    "    print(np.bincount(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We first write a scoring function for clustering so that we can use for GridSearchCV.\n",
    "Take a look at use_scorer under scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Explanation for scoring function</font>\n",
    "\n",
    "Since clustering is an unsupurvised learning method, we need to use 2 steps to obtain the accuracy score:\n",
    "1. Map cluster id to class label (digit id)\n",
    "2. Use mapped class label from step 1 (predicted) and ground truth to get accuracy score\n",
    "\n",
    "In order to manually map the clusters to actual class labels, we propose a way to estimate: compare each cluster centroid to references of all 10 classes. The detailed method is as follows:\n",
    "\n",
    "1. use class labels to split training data set to 10 sets\n",
    "2. compute the mean vector of the 10 sets, i.e. the averaged hand written digits\n",
    "3. Use the 10 mean vectors from above as reference.\n",
    "4. When finish clustering, compare each centroid to all 10 references using $L_2$ to obtain the mapping function. e.g. Suppose centroid $\\mu^{(i)}$ is most similar to reference $r^{(j)}$, then cluster id $i$ should be mapped to class $j$\n",
    "\n",
    "Another important thing to notice is: we have to access our k-means model inside the pipeline to achieve above operations, therefore, we can't use the built-in GridSearchCV algorithm. \n",
    "\n",
    "Hence, we will use the <b>pipeline & StratifiedKFold</b> algorithm directly to implement our GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 (119, 64) average vector dimension (64,)\n",
      "class 1 (133, 64) average vector dimension (64,)\n",
      "class 2 (128, 64) average vector dimension (64,)\n",
      "class 3 (119, 64) average vector dimension (64,)\n",
      "class 4 (120, 64) average vector dimension (64,)\n",
      "class 5 (135, 64) average vector dimension (64,)\n",
      "class 6 (130, 64) average vector dimension (64,)\n",
      "class 7 (122, 64) average vector dimension (64,)\n",
      "class 8 (128, 64) average vector dimension (64,)\n",
      "class 9 (123, 64) average vector dimension (64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "# split data according to their label by: X_train & y_train\n",
    "# and obtain 10 references for mapping function\n",
    "X_train_split = {}\n",
    "for i in range(0, X_train.shape[0]) :\n",
    "    label = y_train[i]\n",
    "    if X_train_split.get(label, 'Never') != 'Never':\n",
    "        X_train_split[label] = np.vstack([X_train_split[label],\n",
    "                                          X_train[i]])\n",
    "    else:\n",
    "        X_train_split[label] = [X_train[i]]\n",
    "\n",
    "X_train_ref = X_train_split[0].mean(axis=0)\n",
    "print('class', 0, X_train_split[0].shape, 'average vector dimension', X_train_ref.shape)\n",
    "for i in range(1,len(X_train_split)):\n",
    "    newrow = X_train_split[i].mean(axis=0)\n",
    "    X_train_ref = np.vstack([X_train_ref,newrow])\n",
    "    print('class', i, X_train_split[i].shape, 'average vector dimension', X_train_ref[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from centroids, get centroid ids & label ids mapping\n",
    "from scipy.spatial import distance\n",
    "def get_cluster_class_mapping(pipe_km, X_train_ref):\n",
    "    X_train_ref_std = pipe_km.named_steps['scl'].transform(X_train_ref)\n",
    "    X_train_ref_reduced = pipe_km.named_steps['pca'].transform(X_train_ref_std)\n",
    "    \n",
    "    reference = X_train_ref_reduced\n",
    "    model = pipe_km.named_steps['km']\n",
    "\n",
    "    centroids = model.cluster_centers_\n",
    "    cluster_ids = model.predict(centroids) # should follow 0, 1,..\n",
    "    class_ids = []\n",
    "    for i in range(0, cluster_ids.shape[0]):\n",
    "        min_class_id = 0\n",
    "        min_dist = distance.euclidean(centroids[i],reference[0])\n",
    "        for j in range(1, len(reference)):\n",
    "            new_dist = distance.euclidean(centroids[i],reference[j])\n",
    "            if(new_dist<min_dist):\n",
    "                min_dist = new_dist\n",
    "                min_class_id = j\n",
    "        class_ids.append(min_class_id)\n",
    "    return class_ids\n",
    "\n",
    "# map cluster id to class id\n",
    "def map_cluster_to_class(y_cluster, ref_class_ids):\n",
    "    return ref_class_ids[y_cluster]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "def clustering_accuracy_score(y_true, y_pred, ref_class_ids):\n",
    "    # y_true: labels (digit ids): 0,1,2,3,4,5,6,7,8,9\n",
    "    # y_pred: cluster ids: 0, 1,...\n",
    "    y_cm=[]\n",
    "    for cid in y_pred:\n",
    "        y_cm.append(map_cluster_to_class(cid, ref_class_ids))\n",
    "    return accuracy_score(y_true=y_true, y_pred=y_cm)\n",
    "\n",
    "clustering_accuracy = make_scorer(clustering_accuracy_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Build a pipeline with standard scaler, PCA, and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_km = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('km', KMeans(init='k-means++', \n",
    "                                  n_init=10,\n",
    "                                  max_iter=500,\n",
    "                                  tol=1e-04,\n",
    "                                  random_state=0,\n",
    "                                 ))\n",
    "                   ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use GridSearchCV to tune hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Explanation on experiments & parameters to tune</font>\n",
    "\n",
    "with reference to [KMeans Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), we keep the following parameters unchange:\n",
    "* init: k-means++ for optimal performance\n",
    "* n_init: 10, the default # of sets of centroids to try, in order to get the best performance\n",
    "* max. iterations allowed: 500\n",
    "* tolerance: 1e-04\n",
    "* random_state: 0\n",
    "\n",
    "The reason why we keep the above parameters unchange is because those parameters are relatively easy to understand in terms of under-fitting and over-fitting. Since the only formally identified hyper-parameters in this pipeline are PCA's n_components & K-Means' k,\n",
    "\n",
    "We are only intersted in the following parameters in the pipeline:\n",
    "* PCA: number of components, i.e. n_components\n",
    "* K-Means: number of clusters, i.e. k\n",
    "\n",
    "To observe influence of pre-processing, we perform following experiments:\n",
    "1. pipeline with standard scalar, PCA & K-means\n",
    "2. pipeline with standard scalar & K-means\n",
    "3. perform K-means on raw data\n",
    "\n",
    "Note*: we know that without standard scalar, data are with high-bias. Hence the PCA performed on un-standardized data is expected to give us bad accuracy. So we skip that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[6, 9, 0, 4, 2, 7, 7, 3, 2, 2, 2, 5, 7, 1, 6, 4, 3, 6, 1, 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80185185185185182"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is just a sample code for using the above functions defined\n",
    "pipe_km.set_params(pca__n_components=20,km__n_clusters=20).fit(X_train)\n",
    "\n",
    "ref_class = get_cluster_class_mapping(pipe_km,X_train_ref)\n",
    "y_pred = pipe_km.predict(X_test)\n",
    "\n",
    "print(cluster_ids)\n",
    "print(ref_class)\n",
    "clustering_accuracy_score(y_test, y_pred, ref_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: pipeline with Standard Scalar & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy:  0.866448790968 when pca__n_components:  19 , km__n_clusters:  23\n"
     ]
    }
   ],
   "source": [
    "# your code: actual experiment\n",
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "else:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pca_range = range(1, 25)\n",
    "k_range = range(1, 25)\n",
    "\n",
    "best_score = 0\n",
    "best_pca = 0\n",
    "best_k = 0\n",
    "\n",
    "for pca_comp in pca_range:\n",
    "    for num_k in k_range:\n",
    "        if Version(sklearn_version) < '0.18':\n",
    "            kfold = StratifiedKFold(y=y_train, \n",
    "                                    n_folds=10,\n",
    "                                    random_state=1)\n",
    "        else:\n",
    "            kfold = StratifiedKFold(n_splits=10,\n",
    "                                    random_state=1).split(X_train, y_train)\n",
    "        scores = []\n",
    "        pipe_km.set_params(pca__n_components=pca_comp,\n",
    "                           km__n_clusters=num_k)\n",
    "        for k, (train, test) in enumerate(kfold):\n",
    "            pipe_km.fit(X_train[train])\n",
    "\n",
    "            y_pred = pipe_km.predict(X_train[test])\n",
    "            ref_class = get_cluster_class_mapping(pipe_km,X_train_ref)\n",
    "            score = clustering_accuracy_score(y_train[test], y_pred, ref_class)\n",
    "            scores.append(score)\n",
    "        mean_score = np.mean(scores)\n",
    "        if(mean_score > best_score):\n",
    "            best_score = mean_score\n",
    "            best_pca = pca_comp\n",
    "            best_k = num_k\n",
    "        # print('finished testing on pca_',pca_comp, ', k_',num_k)\n",
    "print('best accuracy: ', best_score, \n",
    "      'when pca__n_components: ', best_pca,\n",
    "      ', km__n_clusters: ', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.850\n"
     ]
    }
   ],
   "source": [
    "# my best model: \n",
    "# accuracy: 0.866448790968\n",
    "# pca components: 19\n",
    "# clusters: 23\n",
    "\n",
    "best_model = pipe_km.set_params(pca__n_components=19,km__n_clusters=23)\n",
    "best_model.fit(X_train)\n",
    "ref_class = get_cluster_class_mapping(pipe_km,X_train_ref)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print('Test accuracy: %.3f' % clustering_accuracy_score(y_test, y_pred, ref_class))\n",
    "\n",
    "#print('Test accuracy: %.3f' % best_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: pipeline with only Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy:  0.855388291817 , km__n_clusters:  23\n"
     ]
    }
   ],
   "source": [
    "pipe_km_s = Pipeline([('scl', StandardScaler()),\n",
    "                    ('km', KMeans(init='k-means++', \n",
    "                                  n_init=10,\n",
    "                                  max_iter=500,\n",
    "                                  tol=1e-04,\n",
    "                                  random_state=0,\n",
    "                                 ))\n",
    "                   ])\n",
    "def get_cluster_class_mapping_s(pipe_km, X_train_ref):\n",
    "    X_train_ref_std = pipe_km.named_steps['scl'].transform(X_train_ref)\n",
    "    \n",
    "    reference = X_train_ref_std\n",
    "    model = pipe_km.named_steps['km']\n",
    "\n",
    "    centroids = model.cluster_centers_\n",
    "    cluster_ids = model.predict(centroids) # should follow 0, 1,..\n",
    "    class_ids = []\n",
    "    for i in range(0, cluster_ids.shape[0]):\n",
    "        min_class_id = 0\n",
    "        min_dist = distance.euclidean(centroids[i],reference[0])\n",
    "        for j in range(1, len(reference)):\n",
    "            new_dist = distance.euclidean(centroids[i],reference[j])\n",
    "            if(new_dist<min_dist):\n",
    "                min_dist = new_dist\n",
    "                min_class_id = j\n",
    "        class_ids.append(min_class_id)\n",
    "    return class_ids\n",
    "\n",
    "k_range = range(1, 25)\n",
    "\n",
    "best_score = 0\n",
    "best_k = 0\n",
    "\n",
    "for num_k in k_range:\n",
    "    if Version(sklearn_version) < '0.18':\n",
    "        kfold = StratifiedKFold(y=y_train, \n",
    "                                n_folds=10,\n",
    "                                random_state=1)\n",
    "    else:\n",
    "        kfold = StratifiedKFold(n_splits=10,\n",
    "                                random_state=1).split(X_train, y_train)\n",
    "    scores = []\n",
    "    pipe_km_s.set_params(km__n_clusters=num_k)\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        pipe_km_s.fit(X_train[train])\n",
    "\n",
    "        y_pred = pipe_km_s.predict(X_train[test])\n",
    "        ref_class = get_cluster_class_mapping_s(pipe_km_s,X_train_ref)\n",
    "        score = clustering_accuracy_score(y_train[test], y_pred, ref_class)\n",
    "        scores.append(score)\n",
    "    mean_score = np.mean(scores)\n",
    "    if(mean_score > best_score):\n",
    "        best_score = mean_score\n",
    "        best_k = num_k\n",
    "    # print('finished testing on k_',num_k)\n",
    "print('best accuracy: ', best_score, \n",
    "      ', km__n_clusters: ', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.874\n"
     ]
    }
   ],
   "source": [
    "# best model:\n",
    "# accuracy: 0.855388291817\n",
    "# clusters: 23\n",
    "\n",
    "best_s = pipe_km_s.set_params(km__n_clusters=23)\n",
    "best_s.fit(X_train)\n",
    "ref_class = get_cluster_class_mapping_s(pipe_km_s,X_train_ref)\n",
    "y_pred = best_s.predict(X_test)\n",
    "\n",
    "print('Test accuracy: %.3f' % clustering_accuracy_score(y_test, y_pred, ref_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: use K-Means on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy:  0.907816735134 , km__n_clusters:  19\n"
     ]
    }
   ],
   "source": [
    "pipe_km_k = Pipeline([('km', KMeans(init='k-means++', \n",
    "                                  n_init=10,\n",
    "                                  max_iter=500,\n",
    "                                  tol=1e-04,\n",
    "                                  random_state=0,\n",
    "                                 ))])\n",
    "\n",
    "def get_cluster_class_mapping_k(pipe_km, reference):\n",
    "    model = pipe_km.named_steps['km']\n",
    "    centroids = model.cluster_centers_\n",
    "    cluster_ids = model.predict(centroids) # should follow 0, 1,..\n",
    "    class_ids = []\n",
    "    for i in range(0, cluster_ids.shape[0]):\n",
    "        min_class_id = 0\n",
    "        min_dist = distance.euclidean(centroids[i],reference[0])\n",
    "        for j in range(1, len(reference)):\n",
    "            new_dist = distance.euclidean(centroids[i],reference[j])\n",
    "            if(new_dist<min_dist):\n",
    "                min_dist = new_dist\n",
    "                min_class_id = j\n",
    "        class_ids.append(min_class_id)\n",
    "    return class_ids\n",
    "\n",
    "k_range = range(1, 25)\n",
    "\n",
    "best_score = 0\n",
    "best_k = 0\n",
    "\n",
    "for num_k in k_range:\n",
    "    if Version(sklearn_version) < '0.18':\n",
    "        kfold = StratifiedKFold(y=y_train, \n",
    "                                n_folds=10,\n",
    "                                random_state=1)\n",
    "    else:\n",
    "        kfold = StratifiedKFold(n_splits=10,\n",
    "                                random_state=1).split(X_train, y_train)\n",
    "    scores = []\n",
    "    pipe_km_k.set_params(km__n_clusters=num_k)\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        pipe_km_k.fit(X_train[train])\n",
    "\n",
    "        y_pred = pipe_km_k.predict(X_train[test])\n",
    "        ref_class = get_cluster_class_mapping_k(pipe_km_k,X_train_ref)\n",
    "        score = clustering_accuracy_score(y_train[test], y_pred, ref_class)\n",
    "        scores.append(score)\n",
    "    mean_score = np.mean(scores)\n",
    "    if(mean_score > best_score):\n",
    "        best_score = mean_score\n",
    "        best_k = num_k\n",
    "    # print('finished testing on k_',num_k)\n",
    "print('best accuracy: ', best_score, \n",
    "      ', km__n_clusters: ', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.922\n"
     ]
    }
   ],
   "source": [
    "# best model:\n",
    "# accuracy: 0.907816735134\n",
    "# clusters: 19\n",
    "\n",
    "best_k = pipe_km_k.set_params(km__n_clusters=19)\n",
    "best_k.fit(X_train)\n",
    "ref_class = get_cluster_class_mapping_k(best_k,X_train_ref)\n",
    "y_pred = best_k.predict(X_test)\n",
    "\n",
    "print('Test accuracy: %.3f' % clustering_accuracy_score(y_test, y_pred, ref_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Conclusion 1: Best model & best hyper-parameters</font>\n",
    "\n",
    "Based on the above 3 experiments (testing with best model done above as well), we got following results:\n",
    "\n",
    "suppose:\n",
    "* k: # of clusters\n",
    "* n: # of pca components\n",
    "\n",
    "|Method                |best test accuracy  |best hyper-parameters|\n",
    "| :------------------: |:------------------:| :------------------:|\n",
    "| Full pipeline        |0.85                | k = 23, n = 19      |\n",
    "| Standard Scalar + KM |0.874               | k = 23              |\n",
    "| K-Means on Raw data  |0.922               | k = 19              |\n",
    "\n",
    "The highest accuracy score is 0.922\n",
    "\n",
    "Therefore, we found some interesting conclusions:\n",
    "* With # of clusters > 10, the hard clustering algorithm is actually more robust\n",
    "* K-Means performs better on raw data rather than scaled data. The raw data will give us high performance with a simpler model. This is because the raw data can better represents how are the data in different grids should be, in order to form a digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Visualize mis-clustered samples, and provide your explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.922\n",
      "# of misclassified samples:  42\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAEZCAYAAAD2XXAMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npMDV60s4iQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122ece2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "best = pipe_km_k.set_params(km__n_clusters=19)\n",
    "best.fit(X_train)\n",
    "ref_class = get_cluster_class_mapping_k(best,X_train_ref)\n",
    "y_pred = best.predict(X_test)\n",
    "\n",
    "print('Test accuracy: %.3f' % clustering_accuracy_score(y_test, y_pred, ref_class))\n",
    "\n",
    "y_cm=[]\n",
    "for cid in y_pred:\n",
    "    y_cm.append(map_cluster_to_class(cid, ref_class))\n",
    "mis = []# misclassified samples indices\n",
    "for i in range(0,len(y_test)):\n",
    "    if y_cm[i] != y_test[i]:\n",
    "        mis.append(i)\n",
    "print('# of misclassified samples: ', len(mis))\n",
    "\n",
    "num_rows = 6\n",
    "num_cols = 6\n",
    "\n",
    "fig, ax = plt.subplots(nrows=num_rows, ncols=num_cols, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(0, num_rows*num_cols):\n",
    "    img = np.resize(X_test[mis[i]],(8,8))\n",
    "    label = y_test[mis[i]]\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    ax[i].set_title('digit' + str(label)\n",
    "                    +',mis' + str(y_cm[mis[i]]))\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEZCAYAAADCJLEQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDQoAkCUaFAAgSzQoAECW/j+U0X18BRN+OgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1219fe358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot averaged figures (reference points)\n",
    "num_rows = 2\n",
    "num_cols = 5\n",
    "\n",
    "fig, ax = plt.subplots(nrows=num_rows, ncols=num_cols, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(0, num_rows*num_cols):\n",
    "    img = np.resize(X_train_ref[i],(8,8))\n",
    "    label = i\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    ax[i].set_title('digit' + str(label))\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## <font color='purple'>Explanation on mis-clustered samples</font>\n",
    "\n",
    "We plot the averaged digit images for reference, which are used in the cluster-class mapping procedure.\n",
    "\n",
    "All together we have 42 misclassified samples in the best model. For simplicity, we just plot 36 of them to take a look. Observing the mis-clustered samples, we can know:\n",
    "1. The samples are with high noise\n",
    "2. The noise contained in the misclassfied samples usually make them similar to a wrong image in the reference set. e.g. in the plot above, last line, 3-rd image is actually 5, but misclassified as 9. If we take a closer look at the reference set, we will know that the upper part of that image is with high amount of noise, making it darker in the upper right corner. With this effect, the digit appears to be similar to digit 9.\n",
    "\n",
    "Therefore, the misclassification is not random, but because of noise exists in the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tiny image classification\n",
    "\n",
    "We will use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) for image object recognition.\n",
    "The dataset consists of 50000 training samples and 10000 test samples in 10 different classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck; see the link above for more information).\n",
    "The goal is to maximize the accuracy of your classifier on the test dataset after being optimized via the training dataset.\n",
    "\n",
    "You can use any learning models (supervised or unsupervised) or optimization methods (e.g. search methods for hyper-parameters).\n",
    "The only requirement is that your code can run inside an ipynb file, as usual.\n",
    "Please provide a description of your method, in addition to the code.\n",
    "Your answer will be evaluated not only on the test accuracy but also on the creativity of your methodology and the quality of your explanation/description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sample code to get you started\n",
    "\n",
    "This is a difficult classification task.\n",
    "A sample code below, based on a simple fully connected neural network built via Keras, is provided below.\n",
    "The test accuracy is about 43%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2016-12-19 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.1\n",
      "keras 1.1.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a '' -u -d -v -p numpy,keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  (32, 32, 3)\n",
      "50000 training samples\n",
      "10000 test samples\n",
      "10 classes\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load data set\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "img_shape = X_train.shape[1:] # [num_rows, num_cols, num_channels]\n",
    "num_img_pixels = np.prod(img_shape)\n",
    "num_training_samples = X_train.shape[0]\n",
    "num_test_samples = X_test.shape[0]\n",
    "\n",
    "nb_classes = np.sum(np.unique(y_train).shape)\n",
    "\n",
    "print('image shape: ', img_shape)\n",
    "print(X_train.shape[0], 'training samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "# data processing\n",
    "\n",
    "X_train = X_train.reshape(num_training_samples, num_img_pixels)\n",
    "X_test = X_test.reshape(num_test_samples, num_img_pixels)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one hot encoding of labels\n",
    "y_train_ohe = np_utils.to_categorical(y_train)\n",
    "y_test_ohe = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# build a basic network\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(input_dim = num_img_pixels, \n",
    "                output_dim = 50, \n",
    "                init = 'uniform', \n",
    "                activation = 'tanh'))\n",
    "\n",
    "model.add(Dense(output_dim = 50, \n",
    "                init = 'uniform', \n",
    "                activation = 'tanh'))\n",
    "\n",
    "model.add(Dense(output_dim = nb_classes, \n",
    "                init = 'uniform', \n",
    "                activation = 'softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = sgd, \n",
    "              metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "45000/45000 [==============================] - 4s - loss: 2.0287 - acc: 0.2512 - val_loss: 1.8909 - val_acc: 0.3150\n",
      "Epoch 2/5\n",
      "45000/45000 [==============================] - 4s - loss: 1.8056 - acc: 0.3496 - val_loss: 1.7535 - val_acc: 0.3664\n",
      "Epoch 3/5\n",
      "45000/45000 [==============================] - 4s - loss: 1.7134 - acc: 0.3798 - val_loss: 1.7121 - val_acc: 0.3876\n",
      "Epoch 4/5\n",
      "45000/45000 [==============================] - 4s - loss: 1.6551 - acc: 0.4026 - val_loss: 1.6218 - val_acc: 0.4198\n",
      "Epoch 5/5\n",
      "45000/45000 [==============================] - 5s - loss: 1.6062 - acc: 0.4216 - val_loss: 1.6376 - val_acc: 0.4144\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "_ = model.fit(X_train, y_train_ohe, \n",
    "              nb_epoch = 5, \n",
    "              batch_size = 10, \n",
    "              verbose = 1, # turn this on to visualize progress \n",
    "              validation_split = 0.1 # 10% of training data for validation per epoch\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few predictions:  [6 1 9]\n",
      "Training accuracy: 0.42678\n",
      "Test accuracy: 0.4226\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "\n",
    "y_train_pred = model.predict_classes(X_train, verbose=False)\n",
    "print('First few predictions: ', y_train_pred[:3])\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print('Training accuracy:', train_acc)\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test, verbose=False)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Answer (In progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (32, 32, 3)\n",
      "50000 training samples with size: (50000, 32, 32, 3)\n",
      "10000 test samples with size: (10000, 32, 32, 3)\n",
      "feature example [ 0.23137255  0.24313726  0.24705882]\n",
      "class label shape: (50000, 10) , total 10 classes\n"
     ]
    }
   ],
   "source": [
    "# load data set\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# data processing\n",
    "\n",
    "#X_train = X_train.reshape(num_training_samples, num_img_pixels)\n",
    "#X_test = X_test.reshape(num_test_samples, num_img_pixels)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one hot encoding of labels\n",
    "y_train_ohe = np_utils.to_categorical(y_train)\n",
    "y_test_ohe = np_utils.to_categorical(y_test)\n",
    "\n",
    "print('image shape:', img_shape)\n",
    "print(X_train.shape[0], 'training samples with size:', X_train.shape)\n",
    "print(X_test.shape[0], 'test samples with size:', X_test.shape)\n",
    "print('feature example', X_train[0][0][0])\n",
    "print('class label shape:', y_train_ohe.shape, ', total',y_train_ohe.shape[1], 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolution input shape: (32, 32, 3)\n",
      "number of convolutional filters: 16\n",
      "convolution filter size: (4, 4)\n",
      "pooling size (also stride size): (2, 2)\n",
      "10 classes\n"
     ]
    }
   ],
   "source": [
    "# constants \n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]  # input image dimensions\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "nb_filters = 16                  # number of convolutional filters to use\n",
    "filter_size = (4, 4)             # convolotinal filter size\n",
    "pool_size = (2, 2)               # size of pooling area for max pooling\n",
    "num_class = y_train_ohe.shape[1] # number of classes\n",
    "\n",
    "print('convolution input shape:',input_shape)\n",
    "print('number of convolutional filters:', nb_filters)\n",
    "print('convolution filter size:',filter_size)\n",
    "print('pooling size (also stride size):', pool_size)\n",
    "print(num_class, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a network\n",
    "\n",
    "net = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "net.add(Convolution2D(nb_filters, filter_size[0], filter_size[1], \n",
    "                      border_mode='valid',\n",
    "                      input_shape=input_shape,\n",
    "                      activation='relu'))\n",
    "\n",
    "# net.add(Convolution2D(nb_filters, filter_size[0], filter_size[1], \n",
    "#                       border_mode='valid',\n",
    "#                       input_shape=input_shape,\n",
    "#                       activation='relu'))\n",
    "\n",
    "# pooling layers\n",
    "net.add(MaxPooling2D(pool_size=pool_size))\n",
    "net.add(Dropout(0.25))  # reduce overfitting\n",
    "\n",
    "# fully-connected layers\n",
    "net.add(Flatten())\n",
    "# net.add(Dense(output_dim=64, activation = 'tanh'))\n",
    "# net.add(Dropout(0.25))\n",
    "net.add(Dense(output_dim=32, activation = 'tanh'))\n",
    "net.add(Dropout(0.25))\n",
    "net.add(Dense(output_dim=num_class, activation = 'softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9)\n",
    "\n",
    "net.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "45000/45000 [==============================] - 25s - loss: 1.7868 - acc: 0.3563 - val_loss: 1.5056 - val_acc: 0.4658\n",
      "Epoch 2/5\n",
      "45000/45000 [==============================] - 26s - loss: 1.5309 - acc: 0.4493 - val_loss: 1.3805 - val_acc: 0.5076\n",
      "Epoch 3/5\n",
      "45000/45000 [==============================] - 27s - loss: 1.4351 - acc: 0.4864 - val_loss: 1.3359 - val_acc: 0.5210\n",
      "Epoch 4/5\n",
      "45000/45000 [==============================] - 27s - loss: 1.3853 - acc: 0.5076 - val_loss: 1.2624 - val_acc: 0.5522\n",
      "Epoch 5/5\n",
      "45000/45000 [==============================] - 28s - loss: 1.3420 - acc: 0.5227 - val_loss: 1.2465 - val_acc: 0.5626\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "_ = net.fit(X_train, y_train_ohe, \n",
    "              nb_epoch = 5, \n",
    "              batch_size = 10, \n",
    "              verbose = 1, # turn this on to visualize progress \n",
    "              validation_split = 0.1 # 10% of training data for validation per epoch\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few predictions:  [6 9 8]\n",
      "Training accuracy: 0.57612\n",
      "Test accuracy: 0.5578\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "y_train_pred = net.predict_classes(X_train, verbose=False)\n",
    "print('First few predictions: ', y_train_pred[:3])\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print('Training accuracy:', train_acc)\n",
    "\n",
    "y_test_pred = net.predict_classes(X_test, verbose=False)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Your description\n",
    "with the following main parts:\n",
    "\n",
    "<dl>\n",
    "\n",
    "<dt>Introduction</dt>\n",
    "<dd>\n",
    "At a high-level, what are the approaches you considered and why?\n",
    "</dd>\n",
    "\n",
    "<dt>Method</dt>\n",
    "<dd>\n",
    "Describe your entire pipeline, such as data-preprocessing, model selection, and hyper-parameter optpimization.\n",
    "</dd>\n",
    "\n",
    "<dt>Results</dt>\n",
    "<dd>\n",
    "Describe the experimental process you took to arrive at the solution.\n",
    "For example:\n",
    "(1) compare your approach against other approach(es) you have tried, as\n",
    "well as the MLP baseline classifer.\n",
    "(2) compare against different settings of model parameters, e.g. regularization type/strength, number of hidden units or structure of a neural network, types of kernel in a SVM, etc. \n",
    "\n",
    "<dt>Conclusion</dt>\n",
    "<dd>\n",
    "Summarize what you have learned from the experiments and discuss the limitations and potential future improvements of your current method.\n",
    "</dd>\n",
    "\n",
    "<dt>References</dt>\n",
    "<dd>\n",
    "Cite any publically available code, blog posts, research papers, etc. you used or got ideas from.\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>Introduction</font>\n",
    "\n",
    "#### Approach 1: Without ANNs, use GridSearchCV to tune hyper-parameters\n",
    "1. Dimension Reduction: PCA(different kernels), LDA\n",
    "2. Basic Classifiers: Logistic Regression, SVM(different kernels), Random Forest, KNN\n",
    "3. Ensemble learning with above classifiers\n",
    "\n",
    "#### Approach 2: With ANNs, use human intuition to tune hyper-parameters\n",
    "1. Base MLP\n",
    "2. Base MLP with Dimension Reduction(PCA, LDA) before\n",
    "3. Convolutional Neural Network\n",
    "4. Ensemble learning with different CNNs\n",
    "\n",
    "#### Approaches pruned:\n",
    "1. Unsupervised learning using clustering\n",
    "2. Decision Tree Naive Bayes x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>References</font>\n",
    "* Intro to CNN from YouTube chanel Nervana: [(3) Convolutional Neural Networks](https://www.youtube.com/watch?v=SQ67NBCLV98)\n",
    "* CNN process overview from YouTube channel Brandon Rohrer [How Convolutional Neural Networks work](https://www.youtube.com/watch?v=FmpDIaiMIeA)\n",
    "* [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/) on github.io\n",
    "* Keras example code on using CNN on MNIST data set: [keras/examples/mnist_cnn.py](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py)\n",
    "* [Keras Documentation](https://keras.io/) on layers, activations, optimizers\n",
    "* Theano Documentation on [LeNet](http://deeplearning.net/tutorial/lenet.html)\n",
    "* Jason Brownlee's post on Deep Learning, June 24, 2016: [Crash Course on CNN](http://machinelearningmastery.com/crash-course-convolutional-neural-networks/)\n",
    "* Classification [research collection](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130) for dataset CIFAR-10\n",
    "\n",
    "### <font color='purple'>Relative Intuitions on CNN workflow</font>\n",
    "\n",
    "Stacking:\n",
    "* Convolution: add info in each pixel, so that one image becomes a stack of filtered images\n",
    "* Rectified Linear Units (ReLUs): element-wise normalization: negative -> 0\n",
    "* Pooling: shrinking image size\n",
    "\n",
    "Decision making:\n",
    "* Fully-connected layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
